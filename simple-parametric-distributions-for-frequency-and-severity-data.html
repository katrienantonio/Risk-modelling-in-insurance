<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>2 Simple, parametric distributions for frequency and severity data | Risk Modelling in Insurance : a collection of computer labs in R</title>
  <meta name="description" content="Tutorials for the course of Loss Models">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="2 Simple, parametric distributions for frequency and severity data | Risk Modelling in Insurance : a collection of computer labs in R" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Tutorials for the course of Loss Models" />
  

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="2 Simple, parametric distributions for frequency and severity data | Risk Modelling in Insurance : a collection of computer labs in R" />
  
  <meta name="twitter:description" content="Tutorials for the course of Loss Models" />
  

<meta name="author" content="Katrien Antonio and Jonas Crevecoeur">


<meta name="date" content="2019-01-13">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="index.html">
<link rel="next" href="putting-it-all-together-case-study-on-modelling-claim-counts.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />







<script>
$(document).ready(function() {

  $chunks = $('.fold');

  $chunks.each(function () {

    // add button to source code chunks
      $(this).prepend("<div class=\"showopt\">Show Solution</div><br style=\"line-height:22px;\"/>");
 
	$child = $(this).children('div');
	$child.each(function(){
		$(this).children('').attr('class', 'folded');
	});
	$(this).children('pre').attr('class', 'folded');
	$(this).children('p').attr('class', 'folded');
   });

  // hide all chunks when document is loaded
  $('.folded').css('display', 'none')

  // function to toggle the visibility
  $('.showopt').click(function() {
    var label = $(this).html();
    if (label.indexOf("Show") >= 0) {
      $(this).html(label.replace("Show", "Hide"));
    } else {
      $(this).html(label.replace("Hide", "Show"));
    }
    	$child = $(this).siblings('div');
	$child.each(function(){
		$(this).children('pre').slideToggle('fast', 'swing');
	});
	$(this).siblings('pre').slideToggle('fast', 'swing');
	$(this).siblings('p').slideToggle('fast', 'swing');
  });
});
</script>


<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; position: absolute; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; }
pre.numberSource a.sourceLine:empty
  { position: absolute; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: absolute; left: -5em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li class="chapter" data-level="1" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i><b>1</b> Intro</a></li>
<li class="chapter" data-level="2" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html"><i class="fa fa-check"></i><b>2</b> Simple, parametric distributions for frequency and severity data</a><ul>
<li class="chapter" data-level="2.1" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#the-exponential-distribution"><i class="fa fa-check"></i><b>2.1</b> The exponential distribution</a><ul>
<li class="chapter" data-level="2.1.1" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#simulating-data"><i class="fa fa-check"></i><b>2.1.1</b> Simulating data</a></li>
<li class="chapter" data-level="2.1.2" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#exploratory-analysis"><i class="fa fa-check"></i><b>2.1.2</b> Exploratory analysis</a></li>
<li class="chapter" data-level="2.1.3" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#data-visualization-with-ggplot"><i class="fa fa-check"></i><b>2.1.3</b> Data visualization with ggplot</a></li>
<li class="chapter" data-level="2.1.4" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#maximum-likelihood-estimation-mle"><i class="fa fa-check"></i><b>2.1.4</b> Maximum Likelihood Estimation (MLE)</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#discrete-distributions"><i class="fa fa-check"></i><b>2.2</b> Discrete distributions</a><ul>
<li class="chapter" data-level="2.2.1" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#simulating-the-data"><i class="fa fa-check"></i><b>2.2.1</b> Simulating the data</a></li>
<li class="chapter" data-level="2.2.2" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#exploratory-analysis-1"><i class="fa fa-check"></i><b>2.2.2</b> Exploratory analysis</a></li>
<li class="chapter" data-level="2.2.3" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#maximum-likelihood-estimation-mle-1"><i class="fa fa-check"></i><b>2.2.3</b> Maximum Likelihood Estimation (MLE)</a></li>
<li class="chapter" data-level="2.2.4" data-path="simple-parametric-distributions-for-frequency-and-severity-data.html"><a href="simple-parametric-distributions-for-frequency-and-severity-data.html#comparing-fitted-models"><i class="fa fa-check"></i><b>2.2.4</b> Comparing fitted models</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html"><i class="fa fa-check"></i><b>3</b> Putting it all together: case-study on modelling claim counts</a><ul>
<li class="chapter" data-level="3.1" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#read-in-data"><i class="fa fa-check"></i><b>3.1</b> Read in data</a><ul>
<li class="chapter" data-level="3.1.1" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#determining-the-file-path"><i class="fa fa-check"></i><b>3.1.1</b> Determining the file path</a></li>
<li class="chapter" data-level="3.1.2" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#importing-a-.txt-file"><i class="fa fa-check"></i><b>3.1.2</b> Importing a .txt file</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#exploratory-analysis-2"><i class="fa fa-check"></i><b>3.2</b> Exploratory analysis</a><ul>
<li class="chapter" data-level="3.2.1" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#summary-statistics-disregarding-exposure"><i class="fa fa-check"></i><b>3.2.1</b> Summary statistics disregarding exposure</a></li>
<li class="chapter" data-level="3.2.2" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#summary-statistics-taking-into-account-exposure"><i class="fa fa-check"></i><b>3.2.2</b> Summary statistics taking into account exposure</a></li>
<li class="chapter" data-level="3.2.3" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#empirical-probability-distribution"><i class="fa fa-check"></i><b>3.2.3</b> Empirical probability distribution</a></li>
<li class="chapter" data-level="3.2.4" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#the-a-b-0-class-of-distributions"><i class="fa fa-check"></i><b>3.2.4</b> The (a, b, 0) class of distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#fitting-count-distributions"><i class="fa fa-check"></i><b>3.3</b> Fitting count distributions</a><ul>
<li class="chapter" data-level="3.3.1" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#poisson"><i class="fa fa-check"></i><b>3.3.1</b> Poisson</a></li>
<li class="chapter" data-level="3.3.2" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#negative-binomial-1"><i class="fa fa-check"></i><b>3.3.2</b> Negative binomial</a></li>
<li class="chapter" data-level="3.3.3" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#modified-poisson-distributions"><i class="fa fa-check"></i><b>3.3.3</b> Modified Poisson distributions</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#aic-1"><i class="fa fa-check"></i><b>3.4</b> AIC</a></li>
<li class="chapter" data-level="3.5" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#replicating-data-sets"><i class="fa fa-check"></i><b>3.5</b> Replicating data sets</a><ul>
<li class="chapter" data-level="3.5.1" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#poisson-1"><i class="fa fa-check"></i><b>3.5.1</b> Poisson</a></li>
<li class="chapter" data-level="3.5.2" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#nb"><i class="fa fa-check"></i><b>3.5.2</b> NB</a></li>
<li class="chapter" data-level="3.5.3" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#zip"><i class="fa fa-check"></i><b>3.5.3</b> ZIP</a></li>
<li class="chapter" data-level="3.5.4" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#hurdle-poisson-1"><i class="fa fa-check"></i><b>3.5.4</b> Hurdle Poisson</a></li>
</ul></li>
<li class="chapter" data-level="3.6" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#mean-and-variance-of-the-estimated-zip-nb-hurdle-poisson"><i class="fa fa-check"></i><b>3.6</b> Mean and variance of the estimated ZIP, NB, Hurdle Poisson</a><ul>
<li class="chapter" data-level="3.6.1" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#poisson-2"><i class="fa fa-check"></i><b>3.6.1</b> Poisson</a></li>
<li class="chapter" data-level="3.6.2" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#nb-1"><i class="fa fa-check"></i><b>3.6.2</b> NB</a></li>
<li class="chapter" data-level="3.6.3" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#zip-1"><i class="fa fa-check"></i><b>3.6.3</b> ZIP</a></li>
<li class="chapter" data-level="3.6.4" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#hurdle-poisson-2"><i class="fa fa-check"></i><b>3.6.4</b> Hurdle Poisson</a></li>
<li class="chapter" data-level="3.6.5" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#comparison-with-empirical-mean-and-variance"><i class="fa fa-check"></i><b>3.6.5</b> Comparison with empirical mean and variance</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="putting-it-all-together-case-study-on-modelling-claim-counts.html"><a href="putting-it-all-together-case-study-on-modelling-claim-counts.html#conclusion"><i class="fa fa-check"></i><b>3.7</b> Conclusion</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="simulation.html"><a href="simulation.html"><i class="fa fa-check"></i><b>4</b> Simulation</a><ul>
<li class="chapter" data-level="4.1" data-path="simulation.html"><a href="simulation.html#severity"><i class="fa fa-check"></i><b>4.1</b> Severity</a><ul>
<li class="chapter" data-level="4.1.1" data-path="simulation.html"><a href="simulation.html#probability-integral-transform"><i class="fa fa-check"></i><b>4.1.1</b> Probability integral transform</a></li>
<li class="chapter" data-level="4.1.2" data-path="simulation.html"><a href="simulation.html#visualization"><i class="fa fa-check"></i><b>4.1.2</b> Visualization</a></li>
<li class="chapter" data-level="4.1.3" data-path="simulation.html"><a href="simulation.html#expected-loss-with-a-deductible"><i class="fa fa-check"></i><b>4.1.3</b> Expected loss with a deductible</a></li>
</ul></li>
<li class="chapter" data-level="4.2" data-path="simulation.html"><a href="simulation.html#aggregate-loss"><i class="fa fa-check"></i><b>4.2</b> Aggregate loss</a></li>
<li class="chapter" data-level="4.3" data-path="simulation.html"><a href="simulation.html#simulating-future-life-times-of-newborns"><i class="fa fa-check"></i><b>4.3</b> Simulating future life times of newborns</a><ul>
<li class="chapter" data-level="4.3.1" data-path="simulation.html"><a href="simulation.html#importing-the-data"><i class="fa fa-check"></i><b>4.3.1</b> Importing the data</a></li>
<li class="chapter" data-level="4.3.2" data-path="simulation.html"><a href="simulation.html#simulate-the-whole-life-time"><i class="fa fa-check"></i><b>4.3.2</b> Simulate the whole life time</a></li>
<li class="chapter" data-level="4.3.3" data-path="simulation.html"><a href="simulation.html#simulate-the-future-lifetime"><i class="fa fa-check"></i><b>4.3.3</b> Simulate the future lifetime</a></li>
<li class="chapter" data-level="4.3.4" data-path="simulation.html"><a href="simulation.html#visualize-the-data"><i class="fa fa-check"></i><b>4.3.4</b> Visualize the data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="glms.html"><a href="glms.html"><i class="fa fa-check"></i><b>5</b> Generalized Linear Models</a><ul>
<li class="chapter" data-level="5.1" data-path="glms.html"><a href="glms.html#modelling-count-data-with-poisson-regression-models"><i class="fa fa-check"></i><b>5.1</b> Modelling count data with Poisson regression models</a><ul>
<li class="chapter" data-level="5.1.1" data-path="glms.html"><a href="glms.html#a-first-data-set"><i class="fa fa-check"></i><b>5.1.1</b> A first data set</a></li>
<li class="chapter" data-level="5.1.2" data-path="glms.html"><a href="glms.html#fit-a-poisson-glm"><i class="fa fa-check"></i><b>5.1.2</b> Fit a Poisson GLM</a></li>
<li class="chapter" data-level="5.1.3" data-path="glms.html"><a href="glms.html#the-use-of-exposure"><i class="fa fa-check"></i><b>5.1.3</b> The use of exposure</a></li>
<li class="chapter" data-level="5.1.4" data-path="glms.html"><a href="glms.html#analysis-of-deviance-for-glms"><i class="fa fa-check"></i><b>5.1.4</b> Analysis of deviance for GLMs</a></li>
<li class="chapter" data-level="5.1.5" data-path="glms.html"><a href="glms.html#an-example"><i class="fa fa-check"></i><b>5.1.5</b> An example</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="glms.html"><a href="glms.html#overdispersed-poisson-regression"><i class="fa fa-check"></i><b>5.2</b> Overdispersed Poisson regression</a></li>
<li class="chapter" data-level="5.3" data-path="glms.html"><a href="glms.html#negative-binomial-regression"><i class="fa fa-check"></i><b>5.3</b> Negative Binomial regression</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="claims-reserving.html"><a href="claims-reserving.html"><i class="fa fa-check"></i><b>6</b> Claims reserving</a><ul>
<li class="chapter" data-level="6.1" data-path="claims-reserving.html"><a href="claims-reserving.html#goals"><i class="fa fa-check"></i><b>6.1</b> Goals</a></li>
<li class="chapter" data-level="6.2" data-path="claims-reserving.html"><a href="claims-reserving.html#import-a-run-off-triangle"><i class="fa fa-check"></i><b>6.2</b> Import a run-off triangle</a><ul>
<li class="chapter" data-level="6.2.1" data-path="claims-reserving.html"><a href="claims-reserving.html#using-scan"><i class="fa fa-check"></i><b>6.2.1</b> Using <code>scan</code></a></li>
<li class="chapter" data-level="6.2.2" data-path="claims-reserving.html"><a href="claims-reserving.html#using-the-chainladder-package"><i class="fa fa-check"></i><b>6.2.2</b> Using the <code>chainladder</code> package</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="claims-reserving.html"><a href="claims-reserving.html#macks-chain-ladder-calculations"><i class="fa fa-check"></i><b>6.3</b> Mack’s Chain-Ladder calculations</a></li>
<li class="chapter" data-level="6.4" data-path="claims-reserving.html"><a href="claims-reserving.html#glm-analysis-of-a-run-off-triangle"><i class="fa fa-check"></i><b>6.4</b> GLM analysis of a run-off triangle</a></li>
<li class="chapter" data-level="6.5" data-path="claims-reserving.html"><a href="claims-reserving.html#bootstrap-analysis"><i class="fa fa-check"></i><b>6.5</b> Bootstrap analysis</a></li>
<li class="chapter" data-level="6.6" data-path="claims-reserving.html"><a href="claims-reserving.html#more-info"><i class="fa fa-check"></i><b>6.6</b> More info</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Risk Modelling in Insurance : a collection of computer labs in R</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="simple-parametric-distributions-for-frequency-and-severity-data" class="section level1">
<h1><span class="header-section-number">2</span> Simple, parametric distributions for frequency and severity data</h1>
<div id="the-exponential-distribution" class="section level2">
<h2><span class="header-section-number">2.1</span> The exponential distribution</h2>
<p>In this tutorial you will simulate data from an exponential distribution with density</p>
<p><span class="math display">\[ f(x) = \lambda \cdot e^{-\lambda \cdot x}.\]</span></p>
<p>You will then explore and visualize these data. Finally, you will fit an exponential distribution to the data using Maximum Likelihood Estimation (MLE) (as discussed in Chapter 13 of the Loss Models book).</p>
<div id="simulating-data" class="section level3">
<h3><span class="header-section-number">2.1.1</span> Simulating data</h3>
<p>Use the R function <code>rexp</code> to simulate <code>10 000</code> observations from an exponential distribution with mean <span class="math inline">\(5\)</span>.</p>
<ol style="list-style-type: decimal">
<li>Create a variable <code>nsim</code> for the number of simulations;</li>
<li>Create a variable <code>lambda</code> for the <span class="math inline">\(\lambda\)</span> value of the exponential distribution. Hint: the mean of the exponential distribution is given by <span class="math inline">\(\frac{1}{\lambda}\)</span> when using the parametrization given above;</li>
<li>Check the documentation of <code>rexp</code> to see which parametrization <code>R</code> uses for the exponential distribution;</li>
<li>Simulate <code>nsim</code> observations from the exponential distribution. Store the result in the variable <code>sim</code>;</li>
<li>Calculate <code>mean(sim)</code> and verify that the simulated mean is close to <span class="math inline">\(5\)</span>.</li>
</ol>
<div class="fold s">
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># @1. </span>
nsim &lt;-<span class="st"> </span><span class="dv">10000</span>;

<span class="co"># @2.</span>
lambda &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">5</span>;

<span class="co"># @3.</span>
?rexp

<span class="co"># @4. </span>
sim &lt;-<span class="st"> </span><span class="kw">rexp</span>(nsim, <span class="dt">rate =</span> lambda);

<span class="co"># @5.</span>
<span class="kw">mean</span>(sim)</code></pre>
<pre><code>[1] 4.98</code></pre>
</div>
</div>
<div id="exploratory-analysis" class="section level3">
<h3><span class="header-section-number">2.1.2</span> Exploratory analysis</h3>
<ol style="list-style-type: decimal">
<li>Calculate the (empirical) variance of the simulated sample;</li>
<li>Calculate the (emprical) skewness of the simulated sample. The skewness is defined as
<span class="math display">\[ \frac{E((X-\mu)^3)}{\sigma^3}; \]</span></li>
<li>Calculate (empirically) <span class="math inline">\(VaR_{0.95}\)</span> and <span class="math inline">\(TVaR_{0.95}\)</span> for the simulated sample.</li>
</ol>
<div class="fold s">
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># @1. </span>
variance &lt;-<span class="st"> </span><span class="kw">var</span>(sim)
variance</code></pre>
<pre><code>[1] 25.05</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># @2.</span>
mu &lt;-<span class="st"> </span><span class="kw">mean</span>(sim)
sigma &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">var</span>(sim))
numerator &lt;-<span class="st"> </span><span class="kw">mean</span>((sim <span class="op">-</span><span class="st"> </span>mu)<span class="op">^</span><span class="dv">3</span>)

skewness &lt;-<span class="st"> </span>numerator <span class="op">/</span><span class="st"> </span>sigma<span class="op">^</span><span class="dv">3</span>
skewness</code></pre>
<pre><code>[1] 2.032</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># @3.</span>
var95 &lt;-<span class="st"> </span><span class="kw">quantile</span>(sim, <span class="fl">0.95</span>);
var95</code></pre>
<pre><code>  95% 
14.83 </code></pre>
<pre class="sourceCode r"><code class="sourceCode r">tvar95 &lt;-<span class="st"> </span><span class="kw">mean</span>(sim[sim <span class="op">&gt;</span><span class="st"> </span>var95])
tvar95</code></pre>
<pre><code>[1] 19.97</code></pre>
</div>
</div>
<div id="data-visualization-with-ggplot" class="section level3">
<h3><span class="header-section-number">2.1.3</span> Data visualization with ggplot</h3>
<ol style="list-style-type: decimal">
<li>Load the package <code>ggplot2</code>;</li>
<li>You will construct step-by-step the following graph of the empirical CDF</li>
</ol>
<p><img src="_main_files/figure-html/parametric_distributions_empirical_cdf-1.png" width="576" style="display: block; margin: auto;" /></p>
<p>Let <span class="math inline">\(x_{(i)}\)</span> be the <span class="math inline">\(i\)</span>-th simulated value when sorted ascending. The empirical CDF is given by</p>
<p><span class="math display">\[ \hat{F}(x_{(i)}) = \frac{\# \{\text{observations } \leq x_{(i)}\}}{n} = \frac{i}{n}.\]</span></p>
<!-- 2.1. Create two vectors $x$ and $y$ with $x[i] = x_{(i)}$ and $y[i] = \frac{i}{n}$; -->
<p>2.1. Create a new ggplot. Add <code>stat_ecdf</code> using the simulated data;</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">stat_ecdf</span>(<span class="kw">aes</span>(???))</code></pre>
<p>2.2. Change the color of the line to blue by adding the option <code>col = #99CCFF</code> to <code>stat_ecdf</code>;</p>
<p>2.3. Add the black and white ggplot theme, <code>theme_bw()</code>;</p>
<p>2.4. Add <span class="math inline">\(x\)</span> and <span class="math inline">\(y\)</span> labels to the graph. Hint: use <code>xlab</code>, <code>ylab</code>;</p>
<p>2.5. Add a vertical line to indicate the <span class="math inline">\(VaR_{0.95}\)</span>. Check the documentation for <a href="https://www.rdocumentation.org/packages/ggplot2/versions/0.9.1/topics/geom_vline"><code>geom_vline</code></a>;</p>
<p>2.6. Add a title to the plot using <code>ggtitle</code>;</p>
<p>2.7. Change the number of simulations <code>nsim</code> to 50 and observe the effect on the empirical CDF.</p>
<ol start="3" style="list-style-type: decimal">
<li>Use <a href="https://www.rdocumentation.org/packages/ggplot2/versions/0.9.1/topics/geom_density"><code>geom_density</code></a> to create a density plot of the data. Improve the look of the graph using what you learned when creating the plot of the empirical CDF.</li>
</ol>
<p><img src="_main_files/figure-html/parametric_distributions_density-1.png" width="576" style="display: block; margin: auto;" /></p>
<div class="fold s">
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># @1</span>
<span class="kw">library</span>(ggplot2)

<span class="co"># @2.1</span>

p &lt;-<span class="st"> </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_ecdf</span>(<span class="kw">aes</span>(sim))

<span class="co"># @2.2</span>
p &lt;-<span class="st"> </span><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">stat_ecdf</span>(<span class="kw">aes</span>(sim), <span class="dt">col =</span> <span class="st">&quot;#99CCFF&quot;</span>)

<span class="co"># @2.3</span>
p &lt;-<span class="st"> </span>p <span class="op">+</span><span class="st"> </span><span class="kw">theme_bw</span>()

<span class="co"># @2.4</span>
p &lt;-<span class="st"> </span>p <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;x&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ylab</span>(<span class="st">&#39;F(x)&#39;</span>) 

<span class="co"># @2.5</span>
p &lt;-<span class="st"> </span>p <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> var95, <span class="dt">linetype =</span> <span class="st">&#39;dashed&#39;</span>) 

<span class="co"># @2.6</span>
p &lt;-<span class="st"> </span>p <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Empirical CDF&#39;</span>) 

<span class="kw">print</span>(p)</code></pre>
<p><img src="_main_files/figure-html/parametric_distributions_visualization_solution-1.png" width="576" style="display: block; margin: auto;" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># @3</span>
<span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_density</span>(<span class="kw">aes</span>(sim), <span class="dt">fill =</span> <span class="st">&quot;#99CCFF&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;Density&#39;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&#39;x&#39;</span>)</code></pre>
<p><img src="_main_files/figure-html/parametric_distributions_visualization_solution-2.png" width="576" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="maximum-likelihood-estimation-mle" class="section level3">
<h3><span class="header-section-number">2.1.4</span> Maximum Likelihood Estimation (MLE)</h3>
<p>The density of the exponential distribution is given by</p>
<p><span class="math display">\[f(x) = \lambda \cdot e^{-\lambda \cdot x}.\]</span></p>
<p>You have <code>nsim</code> simulated observations <span class="math inline">\(x_{i}, \ldots, x_{nsim}\)</span> from this distribution. In this exercise you look for the MLE of the parameter <span class="math inline">\(\lambda\)</span> using the simulated data.</p>
<ol style="list-style-type: decimal">
<li>Write down (on paper) the formula for the likelihood of the observed data as a function of <span class="math inline">\(\lambda\)</span>;</li>
</ol>
<div class="fold s">
<p>The likelihood for the observed data is
<span class="math display">\[L(\lambda) = \prod_{i=1}^{\text{nsim}} \lambda \cdot e^{-\lambda \cdot x_i}.\]</span></p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Derive (on paper) the loglikelihood;</li>
</ol>
<div class="fold s">
<p>The loglikelihood for the observed data is
<span class="math display">\[l(\lambda) = \sum_{i=1}^{\text{nsim}} \log(\lambda) -\lambda \cdot x_i.\]</span></p>
</div>
<ol start="3" style="list-style-type: decimal">
<li>Compute (on paper) the MLE for <span class="math inline">\(\lambda\)</span>. Hint: put <span class="math inline">\(\frac{d \ell}{ d \lambda}(\hat{\lambda}) = 0\)</span> and solve for the unknown <span class="math inline">\(\lambda\)</span>;</li>
</ol>
<div class="fold s">
<p><span class="math display">\[\frac{d l}{ d \lambda} = \frac{n}{\lambda} -  \sum_{i=1}^{\text{nsim}} x_i\]</span>
This derivative is zero when</p>
<p><span class="math display">\[ \hat{\lambda} = \frac{\text{nsim}}{\sum_{i=1}^{\text{nsim}} x_i}.\]</span>
This is the MLE for <span class="math inline">\(\lambda\)</span>.</p>
</div>
<ol start="4" style="list-style-type: decimal">
<li>You will now find the MLE numerically in R by optimizing the likelihood using the <code>nlm</code> procedure;</li>
</ol>
<p>4.1. Define an R-function <code>loglikelihood</code> which takes as input <span class="math inline">\(\lambda\)</span> and returns the loglikelihood for the simulated sample;</p>
<pre class="sourceCode r"><code class="sourceCode r">loglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(lambda)
{
  loglikelihood &lt;-<span class="st"> </span>???
  <span class="kw">return</span>(loglikelihood)
}</code></pre>
<p>4.2. The <code>nlm</code> procedure minimizes a function. You will minimize the negative loglikelihood <span class="math inline">\(-l(\lambda)\)</span> to find the maximum likelihood estimator <span class="math inline">\(\hat{\lambda}\)</span>. Start from the result of 4.1 and create a function <code>negLoglikelihood</code> which returns the negative loglikelihood;</p>
<p>4.3. The <code>nlm</code> procedure searches for the optimal parameter in the domain <span class="math inline">\((-\infty, \infty)\)</span>. You will use a transformation <span class="math inline">\(\lambda = \exp(\beta)\)</span> and optimize the likelihood for this parameter <span class="math inline">\(\beta \in (-\infty, \infty)\)</span>. Update the function <code>negloglikelihood</code> to take <span class="math inline">\(\beta\)</span> as its input;</p>
<p>4.4. Minimize the function <code>negLoglikelihood</code> you defined in 4.3. using the <code>nlm</code> procedure. Add the option <code>hessian = TRUE</code>;</p>
<p>4.5. Interpret the output of <code>nlm</code>. What is the maximum likelihood estimate for <span class="math inline">\(\beta\)</span> and what about <span class="math inline">\(\lambda\)</span> (see the discussion in Section 13.3 on Variable and interval estimation). Do you find the same result as in 3.?</p>
<p>4.6. You will now construct a <span class="math inline">\(95\%\)</span> confidence interval for the unknown parameter <span class="math inline">\(\beta\)</span> and afterwards for <span class="math inline">\(\lambda\)</span>. Under MLE the actual parameter <span class="math inline">\(\beta\)</span> is asymptotically distributed as (see Chapter 13 on Variance and interval estimation)</p>
<p><span class="math display">\[ \beta \sim \mathcal{N}(\hat{\beta}, \mathcal{I}^{-1}(\hat{\beta})),\]</span>
where <span class="math inline">\(\mathcal{I}\)</span> denotes the Fisher information matrix. You calculate this matrix as the negative of the Hessian, the matrix with the second order derivatives of the log-likelihood, evaluated in <span class="math inline">\(\hat{\beta}\)</span>. Of course, since the Exponential distribution only has one paremeter, the matrix reduces to a scalar.</p>
<p>4.6.1. You added the option <code>hessian = TRUE</code> in <code>nlm</code> to obtain the Hessian (numerically) in the <code>nlm</code> procedure. Use the Hessian to calculate the standard error of the MLE <span class="math inline">\(\hat{\beta}\)</span>. Because you calculated the Hessian of the negative log-likelihood, it suffices to take its inverse to obtain the (asymptotic) variance of the MLE.</p>
<p>4.6.2. A <span class="math inline">\(95\%\)</span> confidence interval for the actual parameter <span class="math inline">\(\beta\)</span> is then given by</p>
<p><span class="math display">\[ [\hat{\beta} - \Phi^{-1}(0.975) \cdot \text{se}_{\hat{\beta}}, \hat{\beta} + \Phi^{-1}(0.975) \cdot \text{se}_{\hat{\beta}}], \]</span>
where <span class="math inline">\(\Phi\)</span> is the CDF of the standard normal distributon. Calculate the <span class="math inline">\(95\%\)</span> confidence interval for the intensity <span class="math inline">\(\beta\)</span> based on the simulated sample. Is the orignal <span class="math inline">\(\beta = \log \lambda\)</span> (used for simulating the data) contained in this interval?</p>
<p>4.6.3 You will now use the delta method (see Section 13.3 in the book) to construct a confidence interval for the unknown <span class="math inline">\(\lambda\)</span>. The MLE for <span class="math inline">\(\lambda\)</span> is obtained from the transformation <span class="math inline">\(\hat{\lambda}=\exp \hat{\beta}\)</span>. The corresponding se is calculated as <span class="math inline">\(se_{\hat{\lambda}} = (\exp \hat{\beta})^2 \cdot \text{se}_{\hat{\beta}}\)</span>. Using these ingredients you are now ready to construct the confidence interval for the unknown parameter <span class="math inline">\(\lambda\)</span>.</p>
<div class="fold s">
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># @1</span>
loglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(lambda)
{
  loglikelihood &lt;-<span class="st"> </span>nsim <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(lambda) <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(lambda <span class="op">*</span><span class="st"> </span>sim)
  <span class="kw">return</span>(loglikelihood)
}

<span class="co"># @2</span>
negLoglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(lambda)
{
  loglikelihood &lt;-<span class="st"> </span>nsim <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(lambda) <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(lambda <span class="op">*</span><span class="st"> </span>sim)
  <span class="kw">return</span>(<span class="op">-</span>loglikelihood)
}

<span class="co"># @3</span>
negLoglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(beta)
{
  lambda &lt;-<span class="st"> </span><span class="kw">exp</span>(beta)
  loglikelihood &lt;-<span class="st"> </span>nsim <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(lambda) <span class="op">-</span><span class="st"> </span><span class="kw">sum</span>(lambda <span class="op">*</span><span class="st"> </span>sim)
  
  <span class="kw">return</span>(<span class="op">-</span>loglikelihood)
}

<span class="co"># @4</span>
fit &lt;-<span class="st"> </span><span class="kw">nlm</span>(negLoglikelihood, <span class="dt">p =</span> <span class="dv">0</span>, <span class="dt">hessian =</span> <span class="ot">TRUE</span>)</code></pre>
<pre><code>Warning in nlm(negLoglikelihood, p = 0, hessian = TRUE): NA/Inf replaced by
maximum positive value</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">fit</code></pre>
<pre><code>$minimum
[1] 26055

$estimate
[1] -1.606

$gradient
[1] -7.251e-05

$hessian
      [,1]
[1,] 10001

$code
[1] 1

$iterations
[1] 8</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># @5</span>
lambdaMLE &lt;-<span class="st"> </span><span class="kw">exp</span>(fit<span class="op">$</span>estimate)
lambdaMLE</code></pre>
<pre><code>[1] 0.2008</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">nsim <span class="op">/</span><span class="st"> </span><span class="kw">sum</span>(sim)</code></pre>
<pre><code>[1] 0.2008</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># @6</span>
sigma.beta &lt;-<span class="st"> </span><span class="kw">sqrt</span>(<span class="kw">solve</span>(fit<span class="op">$</span>hessian))
sigma.lambda &lt;-<span class="st"> </span>sigma.beta <span class="op">*</span><span class="st"> </span>lambdaMLE<span class="op">^</span><span class="dv">2</span>

<span class="kw">c</span>(lambda <span class="op">-</span><span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span>sigma.lambda, lambda <span class="op">+</span><span class="st"> </span><span class="kw">qnorm</span>(<span class="fl">0.975</span>) <span class="op">*</span><span class="st"> </span>sigma.lambda)</code></pre>
<pre><code>[1] 0.1992 0.2008</code></pre>
</div>
</div>
</div>
<div id="discrete-distributions" class="section level2">
<h2><span class="header-section-number">2.2</span> Discrete distributions</h2>
<p>In this computer lab you will simulate discrete data (e.g. claim counts). You will then explore and fit a statistical model to the simulated data set.</p>
<div id="simulating-the-data" class="section level3">
<h3><span class="header-section-number">2.2.1</span> Simulating the data</h3>
<p>You simulate <code>10 000</code> observations from a lognormal distribution (a continuous distribution!). You will then discretize the simulated data by rounding down.</p>
<ol style="list-style-type: decimal">
<li>Simulate <code>10 000</code> observations from a lognormal distribution with density</li>
</ol>
<p><span class="math display">\[f(x) = \frac{1}{x \cdot \sqrt{2 \pi}} \cdot \exp \left( -(\ln(x) + 1.5 \right)^2).\]</span>
Hint: Check the specification of the lognormal distribution in R, <code>?rlnorm</code>.</p>
<ol start="2" style="list-style-type: decimal">
<li>Discretize the data by rounding down using the <code>floor</code> function.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Example of the floor function</span>
x &lt;-<span class="st"> </span><span class="kw">runif</span>(<span class="dv">6</span>)<span class="op">*</span><span class="dv">3</span>
<span class="kw">rbind</span>(<span class="dt">x =</span> x, <span class="dt">floor =</span> <span class="kw">floor</span>(x))</code></pre>
<pre><code>       [,1]  [,2]  [,3]   [,4]  [,5]   [,6]
x     2.576 2.158 0.347 0.4791 2.429 0.6439
floor 2.000 2.000 0.000 0.0000 2.000 0.0000</code></pre>
<div class="fold s">
<pre class="sourceCode r"><code class="sourceCode r">nsim &lt;-<span class="st"> </span><span class="dv">10000</span>;
sim &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="kw">rnorm</span>(nsim, <span class="dt">mean =</span> <span class="fl">-1.5</span>, <span class="dt">sd =</span> <span class="dv">1</span>))

<span class="co"># we only observe the data discrete</span>
sim &lt;-<span class="st"> </span><span class="kw">floor</span>(sim)</code></pre>
</div>
</div>
<div id="exploratory-analysis-1" class="section level3">
<h3><span class="header-section-number">2.2.2</span> Exploratory analysis</h3>
<p>You just obtained simulated discrete data. You now want to investigate which discrete distributions could be good candidates for modelling the simulated data.</p>
<ol style="list-style-type: decimal">
<li>Start by calculating the mean and variance of the simulated data. Is the data underdispersed or overdispersed?</li>
</ol>
<div class="fold s">
<p>The variance is larger than the mean of the data. The data is overdispersed.</p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Which of the following three distributions will most likely describe the data in a good way?</li>
</ol>
<ul>
<li>Binomial</li>
<li>Poisson</li>
<li>Negative binomial</li>
</ul>
<div class="fold s">
<p>The Negative binomial distribution is the best candidate, since this distribution is overdispersed.</p>
</div>
<ol start="3" style="list-style-type: decimal">
<li>Test visually whether the data belongs to the <span class="math inline">\((a, b, 0)\)</span> class, i.e. see whether the relation
<span class="math display">\[ k \cdot \frac{p_k}{p_{k-1}} = a \cdot k + b, \quad k = 1,2, \ldots\]</span>
holds for the simulated data.</li>
</ol>
<p>3.1 Compute the left hand side (lhs) of this relation.</p>
<ul>
<li>Use <code>prop.table(table(???))</code> to get the empirical probability distribution <span class="math inline">\(p_k\)</span>;</li>
<li>The data is heavy tailed and the lhs can become very large when <span class="math inline">\(p_{k-1}\)</span> is small. You check the relation for <span class="math inline">\(k = 1, \dots, 5\)</span>;</li>
<li>Create a vector <span class="math inline">\(k\)</span>, <span class="math inline">\(p_k\)</span> and <span class="math inline">\(p_{k-1}\)</span> for <span class="math inline">\(k = 1,\ldots,5\)</span>;</li>
<li>Combine these results to obtain the lhs of the equation.</li>
</ul>
<p>3.2 Use ggplot to construct a graph containg the points <span class="math inline">\((k, k \cdot \frac{p_k}{p_{k-1}})\)</span>. Your graph should look similar to</p>
<p><img src="_main_files/figure-html/parametric_distributions_abrelation-1.png" width="576" style="display: block; margin: auto;" /></p>
<ul>
<li>Load the package <code>ggplot2</code>;</li>
<li>Create a new ggplot figure. Add a <code>geom_point</code> graphic using the data points <span class="math inline">\((k, lhs)\)</span>;</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">  <span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">    </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(???, ???))</code></pre>
<ul>
<li>Change the color of the points to blue by adding the option <code>col = #99CCFF</code> to <code>geom_point</code>;</li>
<li>You can further customize the graph with <code>theme_bw()</code>, <code>xlab</code>, <code>ylab</code>, <code>ggtitle</code>, <span class="math inline">\(\ldots\)</span>.</li>
</ul>
<p>3.3. Discuss. Is a distribution from the <span class="math inline">\((a, b, 0)\)</span> class a good candidate for this data?</p>
<div class="fold s">
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">mean</span>(sim)</code></pre>
<pre><code>[1] 0.0897</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">var</span>(sim)</code></pre>
<pre><code>[1] 0.1555</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">prob &lt;-<span class="st"> </span><span class="kw">prop.table</span>(<span class="kw">table</span>(sim))
prob</code></pre>
<pre><code>sim
     0      1      2      3      4      5      6      8     10 
0.9319 0.0538 0.0104 0.0023 0.0010 0.0002 0.0001 0.0002 0.0001 </code></pre>
<pre class="sourceCode r"><code class="sourceCode r">k &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="dv">5</span>
pk &lt;-<span class="st"> </span>prob[k<span class="op">+</span><span class="dv">1</span>]
pkmin1 &lt;-<span class="st"> </span>prob[k]

lhs &lt;-<span class="st"> </span>k <span class="op">*</span><span class="st"> </span>pk <span class="op">/</span><span class="st"> </span>pkmin1

<span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(k[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>], lhs[<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>]), <span class="dt">color =</span> <span class="st">&quot;#99CCFF&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() <span class="op">+</span><span class="st"> </span>
<span class="st">  </span><span class="kw">xlab</span>(<span class="st">&quot;k&quot;</span>) <span class="op">+</span>
<span class="st">  </span><span class="kw">ggtitle</span>(<span class="st">&#39;(a, b, 0)-relation test plot&#39;</span>)</code></pre>
<pre><code>Don&#39;t know how to automatically pick scale for object of type table. Defaulting to continuous.</code></pre>
<p><img src="_main_files/figure-html/parametric_distributions_solution_ab-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="maximum-likelihood-estimation-mle-1" class="section level3">
<h3><span class="header-section-number">2.2.3</span> Maximum Likelihood Estimation (MLE)</h3>
<p>You will now fit two count distributions to the simulated data:</p>
<ul>
<li>Geometric</li>
<li>Negative binomial (NB)</li>
</ul>
<div id="geometric" class="section level4">
<h4><span class="header-section-number">2.2.3.1</span> Geometric</h4>
<p>For a Geometric distribution with parameter <span class="math inline">\(p \in [0, 1]\)</span> the probability of observing <span class="math inline">\(k\)</span> events is given by
<span class="math display">\[ P(N = k) = (1-p)^{k} \cdot p.\]</span>
In the Appendix ‘An inventory of discrete distributions’ of the Loss Models book you will find a different parameterization. That is
<span class="math display">\[ P(N=k) = \left(\frac{\theta}{1+\theta}\right)^k \cdot \frac{1}{(1+\theta)}.\]</span>
If you put <span class="math inline">\(p = \frac{1}{1+\theta}\)</span> you can work from the second to the first parametrization. Verify this.</p>
<ol style="list-style-type: decimal">
<li>Derive an expression for the loglikelihood;</li>
</ol>
<div class="fold s">
<p>The likelihood is given by
<span class="math display">\[ L(p) = \prod_{i=1}^{\text{nsim}} P(N = x_i) = \prod_{i=1}^{\text{nsim}} (1-p)^{x_i} \cdot p.\]</span>
The loglikelihood is</p>
<p><span class="math display">\[ l(p) = \sum_{i=1}^{\text{nsim}} \left( \log(1-p) \cdot x_i + \log(p) \right).\]</span></p>
</div>
<ol start="2" style="list-style-type: decimal">
<li>Implement the negative loglikelihood as a function in R;</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r">geom.negLoglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(p)
{
  loglikelihood &lt;-<span class="st"> </span>???
  
  <span class="kw">return</span>(<span class="op">-</span>loglikelihood)
}</code></pre>
<ol start="3" style="list-style-type: decimal">
<li>The probability <span class="math inline">\(p\)</span> can only take values in <span class="math inline">\([0, 1]\)</span>. Change the function <code>geom.negLoglikelihood</code> to take a parameter <span class="math inline">\(\beta \in (-\infty, \infty)\)</span>. Then transform the interval <span class="math inline">\((-\infty, \infty)\)</span> to <span class="math inline">\([0, 1]\)</span> using the logit transform</li>
</ol>
<p><span class="math display">\[ \text{logit}(p) = \log\left( \frac{p}{1-p} \right) = \beta. \]</span></p>
<p>Inverting this expression, you find (verify this!)</p>
<p><span class="math display">\[ p = \frac{\exp(\beta)}{ 1 + \exp(\beta) }.\]</span></p>
<ol start="4" style="list-style-type: decimal">
<li>Maximize the likelihood using the <code>nlm</code> procedure in R and interpret the results.</li>
</ol>
<div class="fold s">
<pre class="sourceCode r"><code class="sourceCode r">geom.negLoglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(beta)
{
  p &lt;-<span class="st"> </span><span class="kw">exp</span>(beta) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(beta))
  
  loglikelihood &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">log</span>(<span class="dv">1</span><span class="op">-</span>p) <span class="op">*</span><span class="st"> </span>sim) <span class="op">+</span><span class="st"> </span>nsim <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(p)
  
  <span class="kw">return</span>(<span class="op">-</span>loglikelihood)
}

fit &lt;-<span class="st"> </span><span class="kw">nlm</span>(geom.negLoglikelihood, <span class="dv">1</span>)</code></pre>
<pre><code>Warning in nlm(geom.negLoglikelihood, 1): NA/Inf replaced by maximum positive
value

Warning in nlm(geom.negLoglikelihood, 1): NA/Inf replaced by maximum positive
value</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">fit</code></pre>
<pre><code>$minimum
[1] 3099

$estimate
[1] 2.411

$gradient
[1] -0.000222

$code
[1] 1

$iterations
[1] 6</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">geom.p &lt;-<span class="st"> </span><span class="kw">exp</span>(fit<span class="op">$</span>estimate) <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">+</span><span class="kw">exp</span>(fit<span class="op">$</span>estimate))
geom.p</code></pre>
<pre><code>[1] 0.9177</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">geom.loglik &lt;-<span class="st"> </span><span class="op">-</span>fit<span class="op">$</span>minimum</code></pre>
</div>
</div>
<div id="negative-binomial" class="section level4">
<h4><span class="header-section-number">2.2.3.2</span> Negative binomial</h4>
<p>You will now go from the one parameter geometric distribution to a two parameter discrete distribution, the Negative Binomial. Its pf is specified as follows:</p>
<p><span class="math display">\[Pr(N=k) = \frac{\Gamma(a+k)}{\Gamma(a) k!}\left(\frac{\mu}{\mu+a}\right)^{k}\left(\frac{a}{\mu+a}\right)^{a}.\]</span></p>
<ol style="list-style-type: decimal">
<li>Follow the same steps as with the geometric distribution to fit the NB distribution to the simulated data.</li>
</ol>
<ul>
<li>The parameters <span class="math inline">\(\mu\)</span> and <span class="math inline">\(a\)</span> can take values on the positive real line <span class="math inline">\([0, \infty)\)</span>. Choose an appropriate transormation to convert this interval to the whole real line, <span class="math inline">\((-\infty, \infty)\)</span>.</li>
</ul>
<div class="fold s">
<pre class="sourceCode r"><code class="sourceCode r">NB.negativeLoglikelihood &lt;-<span class="st"> </span><span class="cf">function</span>(beta)
{
  mu &lt;-<span class="st"> </span><span class="kw">exp</span>(beta[<span class="dv">1</span>])
  a &lt;-<span class="st"> </span><span class="kw">exp</span>(beta[<span class="dv">2</span>])
  
  loglikelihood &lt;-<span class="st"> </span><span class="kw">sum</span>(<span class="kw">lgamma</span>(a <span class="op">+</span><span class="st"> </span>sim) <span class="op">-</span><span class="st"> </span><span class="kw">lgamma</span>(a) <span class="op">-</span><span class="st"> </span><span class="kw">lfactorial</span>(sim) <span class="op">+</span><span class="st"> </span>sim <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(mu<span class="op">/</span>(mu <span class="op">+</span><span class="st"> </span>a)) <span class="op">+</span><span class="st"> </span>a <span class="op">*</span><span class="st"> </span><span class="kw">log</span>(a <span class="op">/</span><span class="st"> </span>(mu <span class="op">+</span><span class="st"> </span>a)))
  
  <span class="kw">return</span>(<span class="op">-</span>loglikelihood)
}

fit &lt;-<span class="st"> </span><span class="kw">nlm</span>(NB.negativeLoglikelihood, <span class="kw">c</span>(<span class="dv">0</span>, <span class="dv">0</span>), <span class="dt">hessian=</span><span class="ot">TRUE</span>)</code></pre>
<pre><code>Warning in nlm(NB.negativeLoglikelihood, c(0, 0), hessian = TRUE): NA/Inf
replaced by maximum positive value

Warning in nlm(NB.negativeLoglikelihood, c(0, 0), hessian = TRUE): NA/Inf
replaced by maximum positive value

Warning in nlm(NB.negativeLoglikelihood, c(0, 0), hessian = TRUE): NA/Inf
replaced by maximum positive value</code></pre>
<pre class="sourceCode r"><code class="sourceCode r">fit</code></pre>
<pre><code>$minimum
[1] 2975

$estimate
[1] -2.411 -1.893

$gradient
[1] 8.958e-04 2.859e-05

$hessian
          [,1]      [,2]
[1,] 562.22093   0.01064
[2,]   0.01064 121.47852

$code
[1] 1

$iterations
[1] 19</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Store the fitted values</span>
nb.mu &lt;-<span class="st"> </span><span class="kw">exp</span>(fit<span class="op">$</span>estimate[<span class="dv">1</span>])
nb.a &lt;-<span class="st"> </span><span class="kw">exp</span>(fit<span class="op">$</span>estimate[<span class="dv">2</span>])

<span class="kw">c</span>(<span class="dt">mu =</span> nb.mu, <span class="dt">a =</span> nb.a)</code></pre>
<pre><code>    mu      a 
0.0897 0.1506 </code></pre>
<pre class="sourceCode r"><code class="sourceCode r">nb.loglik &lt;-<span class="st"> </span><span class="op">-</span>fit<span class="op">$</span>minimum</code></pre>
</div>
</div>
</div>
<div id="comparing-fitted-models" class="section level3">
<h3><span class="header-section-number">2.2.4</span> Comparing fitted models</h3>
<p>You will now compare which model best fits the data using AIC as well as some visual inspection tools.</p>
<div id="aic" class="section level4">
<h4><span class="header-section-number">2.2.4.1</span> AIC</h4>
<p>Suppose that you have a statistical model calibrated on some data. Let <span class="math inline">\(k\)</span> be the number of estimated parameters in the model. Let <span class="math inline">\({\displaystyle {\hat {L}}}\)</span> be the maximum value of the likelihood function for the model. Then the AIC of the investigated model is the following</p>
<p><span class="math display">\[ \text{AIC} = 2 k - 2 \ln ( \hat{L}). \]</span></p>
<p>Given a set of candidate models for the data, the preferred model is the one with the minimum AIC value. Thus, AIC rewards goodness of fit (as assessed by the likelihood function), but it also includes a penalty that is an increasing function of the number of estimated parameters. The penalty discourages overfitting, because increasing the number of parameters in the model almost always improves the goodness of the fit. For more information see <a href="https://en.wikipedia.org/wiki/Akaike_information_criterion">wikipedia</a>.</p>
<ol style="list-style-type: decimal">
<li><p>Calculate the AIC for both fitted models. Hint: <span class="math inline">\(-\ln ( \hat{L})\)</span> is the minimum reached by the <code>nlm</code> procedure.</p></li>
<li><p>Which of the two models does AIC prefer?</p></li>
</ol>
<div class="fold s">
<pre class="sourceCode r"><code class="sourceCode r">aic &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dt">geom =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>geom.loglik,
         <span class="dt">nb =</span> <span class="dv">2</span> <span class="op">*</span><span class="st"> </span><span class="dv">2</span> <span class="op">-</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>nb.loglik)

<span class="co"># the nb distribution has the lowest AIC</span>
<span class="kw">print</span>(aic)</code></pre>
<pre><code>geom   nb 
6200 5955 </code></pre>
</div>
</div>
<div id="visual-inspection" class="section level4">
<h4><span class="header-section-number">2.2.4.2</span> Visual inspection</h4>
<p>Using the fitted parameters you will now simulate new datasets of <code>nsim</code> observations from the Geometric and Negative Binomial distribution. You compare the shapes of the fitted and the original data.</p>
<p><img src="_main_files/figure-html/parametric_distributions_barplot-1.png" width="576" style="display: block; margin: auto;" /></p>
<ol style="list-style-type: decimal">
<li>Simulate a dataset from the Geometric distribution using the fitted parameters;</li>
<li>Simulate a dataset from the Negative binomial distribution using the fitted parameters;</li>
<li>You will now create a barplot using <code>geom_barplot</code>. First the data has to be merged into a single data frame containing two columns:</li>
</ol>
<ul>
<li>x: the simulated values;</li>
<li>method: a string, referring to the method used to simulate the data (i.e. observed, geom or nb).</li>
</ul>
<pre><code> x   method
 0 observed
 0 observed
 0     geom
 1     geom
 0       nb</code></pre>
<p>3.1 Create datasets <code>df.observed</code>, <code>df.geom</code>, <code>df.nb</code> with the simulated data in one column and a string referring to the method used in the other column.</p>
<pre class="sourceCode r"><code class="sourceCode r">df.observed &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> ???, <span class="dt">method =</span> <span class="st">&#39;observed&#39;</span>)</code></pre>
<p>3.2 Combine these three datasets into a single dataset using <code>rbind</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">df &lt;-<span class="st"> </span><span class="kw">rbind</span>(df.observed, df.geom, df.nb);</code></pre>
<ol start="4" style="list-style-type: decimal">
<li>Create a barplot using <a href="https://ggplot2.tidyverse.org/reference/geom_bar.html"><code>geom_bar</code></a>.</li>
</ol>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="kw">aes</span>(???, <span class="dt">fill =</span> ???)) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>()</code></pre>
<ol start="5" style="list-style-type: decimal">
<li><p>By default <code>geom_bar</code> stacks the bars for the different methods. To show the bars sideways add the option <code>position = position_dodge()</code>.</p></li>
<li><p>Discuss. Which distribution best mimicks the original data?</p></li>
</ol>
<div class="fold s">
<pre class="sourceCode r"><code class="sourceCode r">sim.geom &lt;-<span class="st">  </span><span class="kw">rgeom</span>(nsim, geom.p)
sim.nb &lt;-<span class="st"> </span><span class="kw">rnbinom</span>(nsim, <span class="dt">mu =</span> nb.mu, <span class="dt">size =</span> nb.a)

df.observed &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> sim, <span class="dt">method =</span> <span class="st">&#39;observed&#39;</span>)
df.geom &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> sim.geom, <span class="dt">method =</span> <span class="st">&#39;geom&#39;</span>)
df.nb &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">x =</span> sim.nb, <span class="dt">method =</span> <span class="st">&#39;nb&#39;</span>)

df &lt;-<span class="st"> </span><span class="kw">rbind</span>(df.observed, df.geom, df.nb);

<span class="kw">ggplot</span>() <span class="op">+</span>
<span class="st">  </span><span class="kw">geom_bar</span>(<span class="kw">aes</span>(df<span class="op">$</span>x, <span class="dt">fill=</span>df<span class="op">$</span>method), <span class="dt">position =</span> <span class="kw">position_dodge</span>()) <span class="op">+</span>
<span class="st">  </span><span class="kw">theme_bw</span>() </code></pre>
<p><img src="_main_files/figure-html/parametric_distributions_barplot_solution-1.png" width="576" style="display: block; margin: auto;" /></p>
</div>

</div>
</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="index.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="putting-it-all-together-case-study-on-modelling-claim-counts.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
